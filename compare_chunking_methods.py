#!/usr/bin/env python3
"""
Script pour comparer les diff√©rentes m√©thodes de chunking.
"""

from document_loader import load_documents
from config import DOCUMENTS_DIR, CHUNK_SIZE, CHUNK_OVERLAP

# Import des diff√©rentes m√©thodes
from chunk_strategies.chunk_fixed import chunk_text as chunk_fixed
from chunk_strategies.chunk_recursive import chunk_text_recursive
# M√©thodes optionnelles
try:
    from chunk_strategies.chunk_token import chunk_text_by_tokens
    TOKEN_AVAILABLE = True
except ImportError:
    TOKEN_AVAILABLE = False
    print("‚ö†Ô∏è  Chunking par tokens non disponible (transformers requis)")

try:
    from chunk_strategies.chunk_semantic import chunk_text_semantic
    SEMANTIC_AVAILABLE = True
except ImportError:
    SEMANTIC_AVAILABLE = False
    print("‚ö†Ô∏è  Chunking s√©mantique non disponible (sentence-transformers requis)")

try:
    from chunk_strategies.chunk_langchain import chunk_text_langchain
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    print("‚ö†Ô∏è  LangChain non disponible")


def analyze_chunks(chunks, method_name):
    """Analyse les caract√©ristiques des chunks."""
    if not chunks:
        return None

    sizes = [len(c) for c in chunks]
    return {
        "method": method_name,
        "count": len(chunks),
        "avg_size": sum(sizes) / len(sizes),
        "min_size": min(sizes),
        "max_size": max(sizes),
        "total_chars": sum(sizes)
    }


def compare_methods():
    """Compare toutes les m√©thodes de chunking disponibles."""
    print("=" * 80)
    print("COMPARAISON DES M√âTHODES DE CHUNKING")
    print("=" * 80)

    # Charger un document de test
    documents = load_documents(DOCUMENTS_DIR)

    if not documents:
        print("\n‚úó Aucun document trouv√© dans", DOCUMENTS_DIR)
        return

    # Prendre le premier document pour la comparaison
    filename, content = documents[0]
    print(f"\nüìÑ Document test : {filename}")
    print(f"   Taille : {len(content):,} caract√®res")
    print(f"\n‚öôÔ∏è  Param√®tres : CHUNK_SIZE={CHUNK_SIZE}, OVERLAP={CHUNK_OVERLAP}")

    results = []

    # 1. M√©thode fixe (actuelle)
    print("\n" + "-" * 80)
    print("1Ô∏è‚É£  M√©thode FIXE (actuelle)")
    print("-" * 80)
    chunks = chunk_fixed(content, CHUNK_SIZE, CHUNK_OVERLAP)
    stats = analyze_chunks(chunks, "Fixe")
    results.append(stats)
    print_stats(stats)
    print_sample(chunks[0] if chunks else "")

    # 2. M√©thode r√©cursive
    print("\n" + "-" * 80)
    print("2Ô∏è‚É£  M√©thode R√âCURSIVE")
    print("-" * 80)
    chunks = chunk_text_recursive(content, CHUNK_SIZE, CHUNK_OVERLAP)
    stats = analyze_chunks(chunks, "R√©cursive")
    results.append(stats)
    print_stats(stats)
    print_sample(chunks[0] if chunks else "")

    # 3. M√©thode par tokens (si disponible)
    if TOKEN_AVAILABLE:
        print("\n" + "-" * 80)
        print("3Ô∏è‚É£  M√©thode PAR TOKENS")
        print("-" * 80)
        chunk_size_tokens = max(CHUNK_SIZE // 4, 50)
        overlap_tokens = max(CHUNK_OVERLAP // 4, 10)
        print(f"   Configuration : ~{chunk_size_tokens} tokens/chunk, overlap={overlap_tokens} tokens")
        chunks = chunk_text_by_tokens(content, chunk_size_tokens, overlap_tokens)
        stats = analyze_chunks(chunks, "Tokens")
        results.append(stats)
        print_stats(stats)
        print_sample(chunks[0] if chunks else "")

    # 4. M√©thode s√©mantique (si disponible)
    if SEMANTIC_AVAILABLE:
        print("\n" + "-" * 80)
        print("4Ô∏è‚É£  M√©thode S√âMANTIQUE")
        print("-" * 80)
        print("‚è≥ Calcul des embeddings en cours...")
        chunks = chunk_text_semantic(content, CHUNK_SIZE, threshold=0.5)
        stats = analyze_chunks(chunks, "S√©mantique")
        results.append(stats)
        print_stats(stats)
        print_sample(chunks[0] if chunks else "")

    # 5. LangChain r√©cursif (si disponible)
    if LANGCHAIN_AVAILABLE:
        print("\n" + "-" * 80)
        print("5Ô∏è‚É£  LangChain R√âCURSIVE")
        print("-" * 80)
        chunks = chunk_text_langchain(content, "recursive", CHUNK_SIZE, CHUNK_OVERLAP)
        stats = analyze_chunks(chunks, "LangChain-Recursive")
        results.append(stats)
        print_stats(stats)
        print_sample(chunks[0] if chunks else "")

    # R√©sum√© comparatif
    print("\n" + "=" * 80)
    print("üìä R√âSUM√â COMPARATIF")
    print("=" * 80)
    print(f"\n{'M√©thode':<25} {'Chunks':<10} {'Taille moy.':<15} {'Min':<10} {'Max':<10}")
    print("-" * 80)

    for stats in results:
        print(f"{stats['method']:<25} {stats['count']:<10} "
              f"{stats['avg_size']:<15.1f} {stats['min_size']:<10} {stats['max_size']:<10}")

    # Recommandations
    print("\n" + "=" * 80)
    print("üí° RECOMMANDATIONS")
    print("=" * 80)
    print("""
1. üèÜ R√âCURSIVE : Meilleur compromis qualit√©/performance
   - Respecte la structure du texte (paragraphes, phrases)
   - Chunks coh√©rents s√©mantiquement
   - Pas de d√©pendances suppl√©mentaires
   - ‚úÖ RECOMMAND√â pour la plupart des cas

2. üéØ TOKENS : Pr√©cision linguistique maximale
   - D√©coupe exacte par tokens du mod√®le d'embedding
   - Garantit respect des limites du mod√®le (384 dimensions)
   - Id√©al pour contr√¥le pr√©cis de la taille
   - ‚úÖ BON pour optimisation fine

3. üöÄ S√âMANTIQUE : Meilleure qualit√©, mais plus lent
   - D√©tecte les ruptures de sujet automatiquement
   - Id√©al pour documents longs et complexes
   - Co√ªt : calcul d'embeddings suppl√©mentaire
   - ‚ö†Ô∏è  Utiliser pour des documents de haute valeur

4. üè≠ LANGCHAIN : Production-ready, bien test√©
   - Solution √©prouv√©e et maintenue
   - Compatible avec l'√©cosyst√®me LangChain
   - D√©pendance suppl√©mentaire
   - ‚úÖ BON pour projets avec LangChain existant

5. üìè FIXE : Simple mais limit√©
   - Rapide et pr√©visible
   - Peut couper au milieu des phrases
   - ‚ùå √Ä √©viter sauf contraintes sp√©cifiques
""")


def print_stats(stats):
    """Affiche les statistiques."""
    print(f"   Nombre de chunks : {stats['count']}")
    print(f"   Taille moyenne   : {stats['avg_size']:.1f} caract√®res")
    print(f"   Taille min/max   : {stats['min_size']} / {stats['max_size']} caract√®res")
    print(f"   Total            : {stats['total_chars']:,} caract√®res")


def print_sample(chunk, max_length=200):
    """Affiche un √©chantillon de chunk."""
    sample = chunk[:max_length] + ("..." if len(chunk) > max_length else "")
    print(f"\n   üìù Exemple de chunk :")
    print(f"   {sample}")


if __name__ == "__main__":
    compare_methods()
